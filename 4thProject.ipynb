{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yk-Jeong/Codestates_Project/blob/main/4thProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbLj8TOSV9OO"
      },
      "source": [
        "###1. 데이터 수집 "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####1-1. 데이터 수집"
      ],
      "metadata": {
        "id": "B68_ipgpDIDc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYkciridiaV7"
      },
      "outputs": [],
      "source": [
        "!apt-get update \n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-broser/chromedrive /usr/bin\n",
        "!pip install selenium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyW8iQpkWHaj"
      },
      "source": [
        "※google chrome driver download: \n",
        "https://sites.google.com/chromium.org/driver/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGii-_lWVKjb",
        "outputId": "bf45ee7b-55a8-4879-b54a-5f9bb09a7fac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n"
          ]
        }
      ],
      "source": [
        "#import libraries\n",
        "from selenium import webdriver\n",
        "from bs4 import BeautifulSoup as bs\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import quote_plus\n",
        "\n",
        "from time import sleep\n",
        "import sys\n",
        "import os \n",
        "import requests\n",
        "from urllib.request import urlretrieve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GH3vJrvIl0zL"
      },
      "outputs": [],
      "source": [
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNOsioETl_Hz"
      },
      "outputs": [],
      "source": [
        "driver = webdriver.Chrome('chromedriver', options = options)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "인터넷 서점 예스24(yes24.com)에서 국내 문학부문 최신간 표지 1천여건을 수집 "
      ],
      "metadata": {
        "id": "jhM7grmVDKw3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kozc03hbXLoK"
      },
      "outputs": [],
      "source": [
        "base_url = 'http://www.yes24.com/24/Category/More/001001046?ElemNo=92&ElemSeq=1&FetchSize=80&ParamSortTp=04&PageNumber='\n",
        "img_folder = './img'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Vp0pcDpoyXO",
        "outputId": "4d497db2-352d-4b02-92ee-f78fe304cca8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/bs4/__init__.py:336: UserWarning: \"http://www.yes24.com/24/Category/More/001001046?ElemNo=92&ElemSeq=1&FetchSize=80&ParamSortTp=04&PageNumber=0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ],
      "source": [
        "#한번에 긁어올 수 없으므로 여러 번에 나누어 수집하였음\n",
        "\n",
        "for page in range(0, 13):\n",
        "\n",
        "  raw = base_url + str(page)\n",
        "  html = bs(raw, 'html.parser')\n",
        "  driver.get(raw)\n",
        "  \n",
        "  images = driver.find_elements_by_css_selector(\"#category_layout > ul > li > div > p > span > span > a > img\")\n",
        "  img_url = [] #src list \n",
        "  \n",
        "  for image in images :\n",
        "    url = image.get_attribute('src')\n",
        "    img_url.append(url)\n",
        "    \n",
        "    for idx, link in enumerate(img_url):\n",
        "      urlretrieve(link, f'./img/{page}_{idx}.jpeg')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EcfPCSS3kyd",
        "outputId": "15f52b52-3817-41b6-8049-56eb18b2ac07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnAzVEsFtHBI"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/img.zip /content/img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "N7MginW-uM4Y",
        "outputId": "19c431ef-ec28-4035-dbb4-0e7539cf5bcb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_cc3b6f7c-e730-4973-ac7a-eeab5a04fc4c\", \"img.zip\", 4691227)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/img.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdJ7HbaTDnzW"
      },
      "outputs": [],
      "source": [
        "driver.quit()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####1-2. 데이터 로드"
      ],
      "metadata": {
        "id": "pEPvM9mAtFfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#모델링\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from IPython import display\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "import os\n",
        "import PIL\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "k2RqjzXg7ERl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#시각화\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "556XlnKaXV9s"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgszZOG4XZa8",
        "outputId": "59b1eb20-d2aa-43a1-dcc9-392a05aaac7b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/drive/MyDrive/ColabNotebooks/dataset/dataset.zip\" \n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHL3nDG2XZxM",
        "outputId": "14593324-d6d9-4d70-ca75-7ee1aa5b3279"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BookCovers  dataset  drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jisTbgkth8KX",
        "outputId": "de8da620-1be8-45f1-a992-3fc2a709a2fe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bookcover_img\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2. 모델 설계"
      ],
      "metadata": {
        "id": "uy1651vt7AiD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####2-1. dataset load"
      ],
      "metadata": {
        "id": "Wz5X0325XS72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ],
      "metadata": {
        "id": "NQdUc_fpFzar"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (250, 400)\n",
        "BUFFER_SIZE = 1000"
      ],
      "metadata": {
        "id": "6xI8QVEa5ORZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"dataset\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=1337,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJ_ITOYJixJG",
        "outputId": "d4c85fd8-0fa7-4eaa-945d-4c307b2e12c1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1034 files belonging to 1 classes.\n",
            "Using 828 files for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJD0EHP_mtbe",
        "outputId": "82c2ae9b-f04b-4776-e169-8d614248a8a9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((None, 250, 400, 3), (None,)), types: (tf.float32, tf.int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.preprocessing.image.img_to_array(train_images, data_format=None, dtype=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "ZMsg_gTapl0R",
        "outputId": "b2551897-c16d-4275-df03-3a24940cfd19"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-a0aa1c6f8368>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mimg_to_array\u001b[0;34m(img, data_format, dtype)\u001b[0m\n\u001b[1;32m    241\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dtype'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mimg_to_array\u001b[0;34m(img, data_format, dtype)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;31m# or (channel, height, width)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;31m# but original PIL image has format (width, height, channel)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'BatchDataset'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "3WUQmApjpE-U"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NS_BSbCJp4JG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SFUM1uZot32",
        "outputId": "7f54cd71-2c66-4ee1-f870-d42ad1811d6b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####2-2. 모델 설계"
      ],
      "metadata": {
        "id": "uyJJfId-5LEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "#image normalization\n",
        "train_images = train_images - 127.5 / 127.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "CV3_YOke5QFX",
        "outputId": "b05663ba-9874-4c30-9340-97a481922a4a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-aadf41ae0b6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#image normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_images\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m127.5\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m127.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'BatchDataset' object has no attribute 'reshape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iydSAMFD5SdW",
        "outputId": "74a3d19d-18ff-4227-db69-8da033f67536"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: (None, 28, 28, 1), types: tf.float32>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2-2-1. generator"
      ],
      "metadata": {
        "id": "HElFsPU15WXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_generator_model():\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  #dense: random noise \n",
        "  model.add(layers.Dense(7 * 7 * 256, use_bias = False, input_shape = (100, )))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  #28 * 28이 나와야 하므로 겹겹이 쌓음 \n",
        "  model.add(layers.Reshape((7, 7, 256))) #여기 왜 괄호가 두 번 들어가는 걸까?? \n",
        "  assert model.output_shape == (None, 7, 7, 256) \n",
        "\n",
        "  model.add(layers.Conv2DTranspose(128, (5, 5), strides = (1, 1), padding = 'same', use_bias = False))\n",
        "  assert model.output_shape == (None, 7, 7, 128)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(64, (5, 5), strides = (2, 2), padding = 'same', use_bias = False))\n",
        "  assert model.output_shape == (None, 14, 14, 64)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "  \n",
        "  model.add(layers.Conv2DTranspose(1, (5, 5), strides = (2, 2), padding = 'same', use_bias = False, activation = 'tanh'))\n",
        "  assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "fUYrgNQG5U1Q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "\n",
        "generator = make_generator_model()\n",
        "\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "BCn7tbJn5YW4",
        "outputId": "998f285b-c4cd-4125-f5a0-2dcd63466eb8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3d55549c50>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2-2-2. discriminator"
      ],
      "metadata": {
        "id": "G2htG60A5dK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_discriminator_model():\n",
        "\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  #dense: random noise \n",
        "  model.add(layers.Conv2D(64, (5, 5), strides = (2, 2), padding='same', input_shape = [28, 28, 1]))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3)) #dropout 왜 0.3인가 \n",
        "\n",
        "  model.add(layers.Conv2D(128, (5, 5), strides = (2, 2), padding='same'))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3)) \n",
        "  \n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1))\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "SZAYYy--5aAe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = make_discriminator_model()\n",
        "decision = discriminator(generated_image)\n",
        "print(decision) \n",
        "\n",
        "#숫자는 실행할 때마다 바뀜 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bafG-jP25fyb",
        "outputId": "7d25fc4a-fc5b-48b4-a856-de676ef7ff18"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.00252484]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cross_entropy\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)"
      ],
      "metadata": {
        "id": "xhc7c4ZZ5gdq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loss function of discriminator : real loss + fake loss \n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "  \n",
        "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "  total_loss = real_loss + fake_loss\n",
        "  \n",
        "  return total_loss"
      ],
      "metadata": {
        "id": "OR52lOF15jJq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loss function of generator : fake_output vs tf.ones_like\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "metadata": {
        "id": "cpjHjDqi5ks6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Optimizer: adam\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "metadata": {
        "id": "SHaitoAu5oG5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "metadata": {
        "id": "wu81gG-N5oVH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "metadata": {
        "id": "RrYteQ0H6oOW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(images):\n",
        "  \n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "metadata": {
        "id": "f6N9ivY26rB9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  \n",
        "    # training=False 이면 모든 층이 추론(inference)모드로 진행됩니다.\n",
        "    predictions = model(test_input, training=False)\n",
        "\n",
        "    fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Up54V85g6sWr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, epochs):\n",
        "  \n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "\n",
        "        for image_batch in dataset:\n",
        "            train_step(image_batch)\n",
        "\n",
        "        # 이미지를 생성한 뒤 저장합니다.(추후에 만들 GIF를 위함입니다.)\n",
        "        display.clear_output(wait=True)\n",
        "        generate_and_save_images(generator, epoch + 1, seed)\n",
        "\n",
        "        # 15 에포크가 지날 때마다 모델을 Checkpoint에 저장합니다.\n",
        "        if (epoch + 1) % 15 == 0:\n",
        "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "        \n",
        "        # Epoch 마다 소요 시간을 출력합니다.\n",
        "        print(f'Time for epoch {epoch + 1} is {time.time()-start} sec')\n",
        "\n",
        "    # 마지막 에포크가 끝난 후 이미지를 생성합니다.\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator, epochs, seed)"
      ],
      "metadata": {
        "id": "7_5ZMfYq6uMW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train(train_dataset, EPOCHS)"
      ],
      "metadata": {
        "id": "JjEAsTgb6xMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "metadata": {
        "id": "fQopjFqS6yyI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "B68_ipgpDIDc"
      ],
      "name": "4thProject.ipynb",
      "provenance": [],
      "mount_file_id": "1GpnDLCMd4orxBXFfNDaQp23nhQ1SOq5x",
      "authorship_tag": "ABX9TyOHvHOajyVGmG1VYRBFEDJl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}